Paper297	Hybrid Deep Discriminative/Generative Models for Semi-Supervised Learning Discriminative models are often the method of choice in machine learning. Generative mod- els, however, are emerging as a powerful alternative because of their ability to handle unlabeled data, especially in semi-supervised settings. We propose a framework to combine a broad class of discriminative and generative models, interpolating between the two extremes with a multi- conditional likelihood objective. Unlike existing methods, we couple the two components through shared latent variables, and train using recent advances in variational inference. Our framework offers great modeling flexibility, is compatible with modern deep architectures, and results in improvements over the state of the art on the SVHN dataset in the semi-supervised setting.
Paper292	Interpreting Lion Behaviour as Probabilistic Programs We consider the problem of unsupervised learning of meaningful behavioural segments of high-dimensional time-series observations, collected from a pride of African lions. We demonstrate, by way of probabilistic programming, a methodology which allows for quick iteration over models and Bayesian inferences, which enables us to learn meaningful behavioural segments. We introduce a new Bayesian nonparametric (BNP) state-space model, which extends the HDP-HMM with an explicit BNP treatment of duration distributions, to deal with different levels of granularity of the latent behavioural space of the lions. Furthermore, we combine this approach with unsupervised feature learning, using variational autoencoders.
Paper291	Learning the Structure of Probabilistic Sentential Decision Diagrams The probabilistic sentential decision diagram (PSDD) was recently introduced as a tractable representation for probability distributions that are subject to strong logical constraints. Meanwhile, the field of tractable learning saw tremendous success in inducing complex joint distributions from data without constraints, while guaranteeing support for efficient exact inference.This paper studies the efficacy of PSDDs for tractable learning without constraints, for which we develop the first PSDD structure learning algorithm, called LearnPSDD. Experimentals on standard benchmarks show competitive performance, despite the fact that PSDDs are more tractable and restrictive than their alternatives. LearnPSDD compares favorably to sum-product network learners, particularly in terms of model size, which is a proxy for tractability. On four datasets, we report results that to the best of our knowledge are state of the art in tractable learning. Moreover, our algorithm retains the ability to effectively learn PSDDs in structured probability spaces, which is beyond the reach of other representations.
Paper289	Continuously tempered Hamiltonian Monte Carlo Hamiltonian Monte Carlo (HMC) is a powerful Markov chain Monte Carlo (MCMC) method for performing approximate inference in complex probabilistic models of continuous variables. In common with many MCMC methods however the standard HMC approach performs poorly in distributions with multiple isolated modes. We present a method for augmenting the Hamiltonian system with an extra continuous temperature control variable which allows the dynamic to bridge between sampling a complex target distribution and a simpler unimodal base distribution. This augmentation both helps improve mixing in multimodal targets and allows the normalisation constant of the target distribution to be estimated. The method is simple to implement within existing HMC code, requiring only a standard leapfrog integrator. We illustrate experimentally that the method is competitive with annealed importance sampling and simulating tempering methods at sampling from challenging multimodal distributions and estimating their normalising constants.
Paper278	A Probabilistic Framework for Multi-Label Learning with Unseen Labels We present a probabilistic framework for multi-label learning for a challenging setting when the test data may require predicting the presence/absence of labels that were not available at the training time. To address this, we develop a probabilistic model that leverages the co-occurrence statistics of the labels via a joint generative model for the label matrix (which denotes the label presence/absence for each example) and for the label co-occurrence matrix (which denotes how many times a pair of labels co-occurs with each other). The label co-occurrence statistics can be obtained from external data sources in an unsupervised manner. In addition to handling the unseen labels at test time, leveraging the co-occurrence information may also help in the standard multi-label learning setting, especially if the number of training examples is very small and/or the label matrix of training examples has a large fraction of missing entries. We present our experimental results on a number of benchmark data sets, comparing our model with various baselines, and show that our model performs favorably when handling unseen labels.
Paper276	Online Constrained Model-based Reinforcement Learning Applying reinforcement learning to robotic systems poses a number of challenging problems. A key requirement is the ability to handle continuous state and action spaces while remaining within a limited time and resource budget. Additionally, for safe operation, the system must make robust decisions under hard constraints. To address these challenges, we propose a model based approach that combines Gaussian Process regression and Receding Horizon Control. Using sparse spectrum Gaussian Processes, we extend previous work by updating the dynamics model incrementally from a stream of sensory data. This results in an agent that can learn and plan in real-time under non-linear constraints. We test our approach on a cart pole swing-up environment and demonstrate the benefits of online learning on an autonomous racing task. The environment’s dynamics are learned from limited training data and can be reused in new task instances without retraining.
Paper267	Holographic Feature Representations of Deep Networks It is often asserted that deep networks learn ``"features", traditionally expressed by the activations of intermediate nodes. We explore an alternative concept by defining features as partial derivatives of model output with respect to model parameters---extending a simple yet powerful idea from generalized linear models. The resulting features are not equivalent to node activations, and we show that they can induce a holographic representation of the complete model: the network's output on given data can be exactly replicated by a simple linear model over such features extracted from any ordered cut. We demonstrate useful advantages for this feature representation over standard representations based on node activations.
Paper266	Learning Treatment-Response Models from Multivariate Longitudinal Data Treatment effects can be estimated from observational data as the difference in potential outcomes. In this paper, we address the challenge of estimating the potential outcome when treatment-dose levels can vary continuously over time. Further, the outcome variable may not be measured at a regular frequency. Our proposed solution represents the treatment response curves using linear time-invariant dynamical systems---this provides a flexible means for modeling response over time to highly variable dose curves. Moreover, for multivariate data, the proposed method: uncovers shared structure in treatment response and the baseline across multiple markers; and, flexibly models challenging correlation structure both across and within signals over time. For this, we build upon the framework of multiple-output Gaussian Processes. On simulated and a challenging clinical dataset, we show significant gains in accuracy over state-of-the-art models. 
Paper263	Why Rules are Complex: Real-Valued Probabilistic Logic Programs are not Fully Expressive This paper explores what can and cannot be represented by probabilistic logic programs. Propositional logic programs can represent any distribution, because they can be acyclic. For relational domains with fixed populations, the probabilistic parameters can be derived as the solutions to polynomial equations. Unfortunately, sometimes they only have complex-valued solutions. This proves that probabilistic logic programs, even with arbitrarily real-valued parameters, cannot represent all distributions. Moreover, they cannot approximate all distributions. Allowing the parameters to be complex numbers, we present a natural truly-cyclic canonical representation that with probability 1 can represent all distributions for relational domains with fixed populations, and, unlike standard representations, has no redundant parameters. Our results provide strong negative results on what probabilistic logic programs can represent using real numbers.
Paper259	Improving Optimization-Based Approximate Inference by Clamping Variables While central to the application of probabilistic models to discrete data, the problem of marginal inference is in general intractable and efficient approximation schemes need to exploit the problem structure. Recently, there have been efforts to develop inference techniques that do not necessarily make factorization assumptions about the distribution, but rather exploit the fact that sometimes there exist efficient algorithms for finding the MAP configuration. In this paper, we theoretically prove that for discrete multi-label models the bounds on the partition function obtained by two of these approaches, Perturb-and-MAP and the bound from the infinite Renyi divergence, can be only improved by clamping any subset of the variables. For the case of log-supermodular models we provide a more detailed analysis and develop a set of efficient strategies for choosing the order in which the variables should be clamped. Finally, we present a number of numerical experiments showcasing the improvements obtained by the proposed methods on several models.
Paper255	How Good Are My Predictions? Efficiently Approximating Precision-Recall Curves for Massive Datasets Large scale machine learning produces massive datasets whose items are often associated with a confidence level and can thus be ranked. However, computing the precision of these resources requires human annotation, which is prohibitively expensive and is often skipped. We consider the problem of cost-effectively approximating precision-recall (PR) or ROC curves for such systems. Our novel approach, called PAL, provides theoretically guaranteed lower and upper bounds on the underlying precision function while relying on only $\bigOh(\log n)$ annotations for a resource with $n$ items. This contrasts favorably with $\Theta(\sqrt{n \log n})$ annotations needed by commonly used sampling based methods. Our key insight is to capitalize on a natural monotonicity property of the underlying confidence-based ranking. PAL provides tight bounds for PR curves using, e.g., only 17K annotations for resources with 200K items and 48K annotations for resources with 2B items. We illustrate our approach by evaluating the much utilized PPDB paraphrase database and a recently introduced Science KB. 
Paper225	Importance Sampling for Fair Policy Selection We consider the problem of off-policy policy selection in reinforcement learning: using historical data generated from running one policy to compare two or more policies. We show that approaches based on importance sampling can be unfair—they can select the worse of the two policies more often than not. We give two examples where the unfairness of importance sampling could be practically concerning. We then present sufficient conditions to theoretically guarantee fairness and a related notion of safety. Finally, we provide a practical importance sampling-based estimator to help mitigate one of the systematic sources of unfair- ness resulting from using importance sampling for policy selection. 
Paper217	Stein Variational Adaptive Importance Sampling We propose a novel adaptive importance sampling algorithm which incorporates Stein variational gradient decent algorithm(SVGD) with importance sampling(IS). Our algorithm leverages the nonparametric transforms defined in SVGD to iteratively decrease the KL divergence between our importance proposal and the target distribution. The advantages of this idea are two folds: first, it enables our algorithm to inherit more theoretical interpretability of IS than SVGD; second, we do not restrict the choice of our importance proposal from predefined distribution families as in traditional adaptive IS. Empirical experiments demonstrate that our algorithm performs better than the traditional adaptive IS. In addition, our algorithm achieves comparable results with Hamiltonian annealing importance sampling when employed to estimate the partition functions of graphical models and evaluate the log-likelihoods of deep generative models.
Paper209	A Reinforcement Learning Approach to Weaning of Mechanical Ventilation in Intensive Care Units The management of invasive mechanical ventilation, and the regulation of sedation and analgesia during ventilation, constitutes a major part of the care of patients admitted to intensive care units. Both prolonged dependence on mechanical ventilation and premature extubation are associated with increased risk of complications and higher hospital costs, but clinical opinion on the best protocol for weaning patients off the ventilator varies. This work looks to develop a decision support tool that uses available information to predict time to extubation readiness and recommend a personalized regime of sedation dosage and ventilator support. To this end, we employ off-policy reinforcement learning algorithms to determine the best action at a given patient state from sub-optimal historical ICU data. We compare treatment policies from fitted Q-iteration with extremely randomized trees and with feedforward neural networks, and demonstrate that the policies learnt show promise in recommending weaning protocols with improved outcomes, in terms of minimizing the rate of reintubation and closer regulation of physiological stability.
Paper180	Analysis of Thompson Sampling for Stochastic Sleeping Bandits We study a variant of the stochastic multi-armed bandit problem where the set of available arms varies adversarially with time (also known as the sleeping bandit problem). We focus on the Thompson Sampling algorithm, and consider a regret notion defined with respect to the best available arm. Our main result is an O(log T) regret bound for Thompson Sampling, which generalizes a similar bound known for this algorithm from the classical bandit setting. Our bound also matches (up to constants) the best-known lower bound for the sleeping bandit problem. We show via simulations that Thompson Sampling outperforms the UCB-style AUER algorithm for sleeping bandit problem
Paper173	Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural Networks with Many More Parameters than Training Data One of the defining properties of deep learning is that models are chosen to have many more parameters than available training data. In light of this capacity for overfitting, it is remarkable that simple algorithms like SGD reliably return solutions with low test error. One roadblock to explaining these phenomena in terms of implicit regularization, structural properties of the solution, and/or easiness of the data is that many learning bounds are quantitatively vacuous in this "deep learning" regime. In order to explain generalization, we need nonvacuous bounds. We return to an idea by Langford and Caruana (2001), who used PAC-Bayes bounds to compute nonvacuous numerical bounds on generalization error for \emph{stochastic} two-layer two-hidden-unit neural networks via a sensitivity analysis. By optimizing the PAC-Bayes bound directly, we are able to extend their approach and obtain nonvacuous generalization bounds for deep stochastic neural network classifiers with millions of parameters trained on only tens of thousands of examples. We connect our findings to recent and old work on flat minima and MDL-based explanations of generalization.
Paper171	A Practical Method for Solving Contextual Bandit Problems Using Decision Trees Many efficient algorithms with strong theoretical guarantees have been proposed for the contextual multi-armed bandit problem. However, applying these algorithms in practice can be difficult because they require domain expertise to build appropriate features and to tune their parameters. We propose a new method for the contextual bandit problem that is simple, practical, and can be applied with little or no domain expertise. Our algorithm relies on decision trees to model the context-reward relationship. Decision trees are non-parametric, interpretable, and work well without hand-crafted features. To guide the exploration-exploitation trade-off, we use a bootstrapping approach which abstracts Thompson sampling to non-Bayesian settings. We also discuss several computational heuristics and demonstrate the performance of our method on several datasets.
Paper160	On Loopy Belief Propagation -- Local Stability Analysis for Non-Vanishing Fields We obtain all fixed points of belief propagation and provide a local stability analysis. In this work we consider pairwise interactions and binary random variables and investigates the influence of non-vanishing fields and finite-size graphs on the performance of belief propagation. Local stability is heavily influenced by these properties. We show how non-vanishing fields help to achieve convergence and to increase the accuracy of belief propagation. In the antiferromagnetic case we show close connections between the existence of multiple solutions, the capability of belief propagation (with damping) to converge, and the underlying graph structure. Further we provide insights into why finite-size graphs behave better than infinite-size graphs.
Paper147	Decoupling Homophily and Reciprocity with Latent Space Network Models Networks form useful representations of data arising in various physical and social domains. In this work, we consider dynamic networks such as communication networks in which links connecting pairs of nodes appear over continuous time. We adopt a point process modeling approach, and study latent space models which embed network nodes into Euclidean space. We propose models to capture two different aspects of dynamic network data: (i) that communication occurs at a higher rate between individuals with similar features (homophily), and (ii) that individuals tend to reciprocate communications from other nodes, but in a manner that varies across individuals. Our framework marries ideas from point process models, like Poisson and Hawkes processes, with ideas from latent space models of static networks. We evaluate our models over a range of tasks on real-world datasets and show that a dual latent space, which accounts for heterogeneity in both reciprocity and homophily, significantly improves performance for both dynamic and static link prediction. 
Paper137	Stochastic Bandit Models for Delayed Conversions  Online advertising and product recommendation are important domains of applications for multi-armed bandit methods. In these fields, the reward that is immediately available is most often only a proxy for the actual outcome of interest, which we refer to as a 'conversion'. For instance, in web advertising, clicks can be observed within a few seconds after an ad display but the corresponding sale --if any-- will take hours, if not days to happen. This paper proposes and investigates a new stochastic multi-armed bandit model in the framework proposed by Chapelle (2014) --based on empirical studies in the field of web advertising-- in which each action may trigger a future reward that will then happen with a stochastic delay. We assume that the probability of conversion associated with each action is unknown while the distribution of the conversion delay is known, distinguishing between the (idealized) case where the conversion events may be observed whatever their delay and the more realistic setting in which late conversions are censored. We provide performance lower bounds as well as two simple but efficient algorithms based on the UCB and KLUCB frameworks. The latter algorithm, which is preferable when conversion rates are low, is based on a Poissonization argument, of independent interest in other settings where aggregation of Bernoulli observations with different success probabilities is required.
Paper120	Interpreting and using CPDAGs with background knowledge We consider maximally oriented partially directed acyclic graphs (maximal PDAGs). These graphs occur, for example, as a result of applying background knowledge of certain edge orientations to a completed partially directed acyclic graph (CPDAG). While background knowledge is often available, current causal methods developed for CPDAGs cannot be applied to the resulting graphical output. In this paper, we solve two problems for maximal PDAGs: we develop methodology to read off possible ancestral relationships and we adapt some existing graphical methods for estimating total causal effects. Specifically, we adapt the graphical criteria for covariate adjustment, as well as the IDA and joint-IDA frameworks. We also present a simulation study that illustrates the gain in identifiability of total causal effects as the background knowledge increases.
Paper109	Approximation Complexity of Maximum A Posteriori Inference in Sum-Product Networks We discuss the computational complexity of approximating maximum a posteriori inference in sum-product networks. We first show NP-hardness in trees of height two by a reduction from maximum independent set; this implies non-approximability within a sublinear factor. We show that this is a tight bound, as we can find an approximation within a linear factor in networks of height two. We then show that, in trees of height three, it is NP-hard to approximate the problem within a factor $2^{f(n)}$ for any sublinear function $f$ of the size of the input $n$. Again, this bound is tight, as we prove that the usual max-product algorithm finds (in any network) approximations within factor $2^{c \cdot n}$ for some constant $c < 1$. Last, we present a simple algorithm, and show that it provably produces solutions at least as good as, and potentially much better than, the max-product algorithm. We empirically analyze the proposed algorithm against max-product using synthetic and real-world data.
Paper69	Balanced Mini-batch Sampling for SGD Using Determinantal Point Processes We study a mini-batch diversification scheme for stochastic gradient descent (SGD) in machine learning. While SGD uniformly subsamples mini-batches from the data, we diversify our mini-batch by using the Determinantal Point Processes (DPPs). DPPs repulsively penalize data points in the same mini-batch which show a high degree of similarity, where similarity is measured in terms of a kernel. This scheme allows us to balance our original dataset, and leads to stochastic gradients with lower variance. We term this approach Balanced Mini-batch SGD (BM-SGD). We show theoretically that this approach contains both regular SGD and stratified sampling as limiting cases, and that more generally BM-SGD is a generalization of stratified sampling to cases where no discrete features exist to bin the data into groups. We show experimentally that our method results more interpretable and diverse features in unsupervised setups, and in better classification accuracies in supervised setups.
Paper62	Near-Optimal Interdiction of Factored MDPs Stackelberg games have been widely used to model interactions between attackers and defenders in a broad array of security domains. One related approach involves plan interdiction, whereby a defender chooses a subset of actions to block (remove), and the attacker constructs an optimal plan in response. In previous work, this approach has been introduced in the context of Markov decision processes (MDPs). The key challenge, however, is that the state space of MDPs grows exponentially in the number of state variables. We propose a novel scalable MDP interdiction framework which makes use of factored representation of state, using Fourier representation for representing a value function over a boolean space. We demonstrate that our approach is significantly more scalable, while resulting in near-optimal interdiction decisions.
Paper54	An Efficient Minibatch Acceptance Test for Metropolis-Hastings We present a novel Metropolis-Hastings method for large datasets that uses small expected-size minibatches of data. Previous work on reducing the cost of Metropolis- Hastings tests yield variable data consumed per sample, with only constant factor reductions versus using the full dataset for each sample. Here we present a method that can be tuned to provide arbitrarily small batch sizes, by adjusting either proposal step size or temperature. Our test uses the noise-tolerant Barker acceptance test with a novel additive correction variable. The resulting test has similar cost to a normal SGD update. Our experiments demonstrate several order-of-magnitude speedups over previous work.
Paper48	Inverse Reinforcement Learning via Deep Gaussian Process We propose a new approach to inverse reinforcement learning (IRL) based on the deep Gaussian process (deep GP) model, which is capable of learning complicated reward structures with few demonstrations. Our model stacks multiple latent GP layers to learn abstract representations of the state feature space, which is linked to the demonstrations through the Maximum Entropy learning framework. Incorporating the IRL engine into the nonlinear latent structure renders existing deep GP inference approaches intractable. To tackle this, we develop a non-standard variational approximation framework which extends previous inference schemes. This allows for approximate Bayesian treatment of the feature space and guards against overfitting. Carrying out representation and inverse reinforcement learning simultaneously within our model outperforms state-of-the-art approaches, as we demonstrate with experiments on standard benchmarks (``"object world",``"highway driving") and a new benchmark (``"binary world").
Paper32	Provable Inductive Robust PCA via Iterative Hard Thresholding The robust PCA problem, wherein, given an input data matrix that is the superposition of a low-rank matrix and a sparse matrix, we aim to separate out the low-rank and sparse components, is a well-studied problem in machine learning. One natural question that arises is that, as in the inductive setting, if features are provided as input as well, can we hope to do better? Answering this in the affirmative, the main goal of this paper is to study the robust PCA problem while incorporating feature information. In contrast to previous works in which recovery guarantees are based on the convex relaxation of the problem, we propose a simple iterative algorithm based on hard-thresholding of appropriate residuals. Under weaker assumptions than previous works, we prove the global convergence of our iterative procedure; moreover, it admits a much faster convergence rate and lesser computational complexity per iteration. In practice, through systematic synthetic and real data simulations, we confirm our theoretical findings regarding improvements obtained by using feature information.
Paper11	Causal Consistency of Structural Equation Models Complex systems can be modelled at various levels of detail. Ideally, causal models of the same system should be consistent with one another in the sense that they agree in their predictions of the effects of interventions. We formalise this notion of consistency in the case of Structural Equation Models (SEMs) by introducing exact transformations between SEMs. This provides a general language to consider, for instance, the different levels of description in the following three scenarios: (a) models with large numbers of variables versus models in which the `irrelevant' or unobservable variables have been marginalised out; (b) micro-level models versus macro-level models in which the macro-variables are aggregate features of the micro-variables; (c) dynamical time series models versus models of their stationary behaviour. Our analysis stresses the importance of well specified interventions in the causal modelling process and sheds light on the interpretation of cyclic SEMs.
Paper6	Near-Orthogonality Regularization in Kernel Methods Kernel methods perform nonlinear learning in a high-dimensional reproducing kernel Hilbert space. Their large model-capacity leads to high representational power, but also incurs substantial risk of overfitting. To alleviate this problem, we propose a new regularization approach -- near-orthogonality regularization, which encourages the RKHS functions to be close to orthogonal. This effectively imposes a structural constraint over the function space, which reduces model complexity and improves generalization performance. Encouraging orthogonality can also reduce model size without compromising modeling power and is capable of capturing infrequent patterns. We define a family of orthogonality-promoting regularizers by encouraging the Gram matrix of the RKHS functions to be close to an identity matrix, where the closeness is measured by Bregman matrix divergence. We apply these regularizers to kernel distance metric learning and kernel sparse coding, and develop an efficient ADMM based algorithm to solve the regularized optimization problems. We analyze how near-orthogonality affects the generalization performance of kernel methods. The results suggest that the closer the functions are to orthogonality, the smaller the generalization error is. Experiments demonstrate the efficacy of near-orthogonality regularization in kernel methods.
